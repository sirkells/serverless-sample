trigger:
- main

# pool:
#   vmImage: 'ubuntu-latest'

# stages:
# - stage: Build
#   jobs:
#   - job: FirstJob
#     steps:
#     - bash: echo $(PipelineLevelVariable)
#     - bash: echo $(Build.BuildNumber)
#     - bash: echo $(Build.BuildId)
#     - bash: echo $(Build.SourceBranchName)
#     - bash: ls -R $(Build.SourcesDirectory)
#     - bash: ls -R $(System.DefaultWorkingDirectory)
#     - bash: ls -R $(Build.ArtifactStagingDirectory)
parameters:
  # Path for terraform directory
  - name: "path"
    type: string
    default: "/home/vsts/work/1/s/infrastructure"
  # Terraform version to use, default use TF_VERSION variable
  # Job Name for reference
  - name: "jobName"
    type: string
    default: "DeployInfra"
  # AWS Connection Name for Terraform Backend
  - name: "awsConnection"
    type: string
    default: "cicd_credential"

stages:
# - stage: BuildArtifact
#   jobs:
#   - job: BuildLambdaFunction
#     pool:
#       vmImage: 'ubuntu-latest'
#     continueOnError: false
#     steps:
#       - task: NodeTool@0
#         inputs:
#           versionSpec: '14.x'
#         displayName: 'Install Node.js'
#       - script: |
#           npm install
#           npm run build
#         workingDirectory: $(System.DefaultWorkingDirectory)/backend
#         displayName: 'NPM install, lint, and test'
#       - task: ArchiveFiles@2
#         inputs:
#           rootFolderOrFile: '$(Build.SourcesDirectory)/backend/build/'
#           includeRootFolder: false
#           archiveType: 'zip'
#           archiveFile: '$(Build.ArtifactStagingDirectory)/rest_api.zip'
#           replaceExistingArchive: true
#           verbose: true
#       - task: PublishPipelineArtifact@1
#         inputs:
#           targetPath: '$(Pipeline.Workspace)'
#           artifact: 'rest_api'
#           publishLocation: 'pipeline'

# - stage: DeployApp
#   dependsOn: BuildArtifact
#   jobs:
#   - deployment: DevDeployment
#     pool:
#       vmImage: 'ubuntu-latest'
#     environment: 'Development'
#     strategy:
#       runOnce:
#         deploy:
#           steps:
#           - task: S3Upload@1
#             inputs:
#               awsCredentials: ${{ parameters.awsConnection }}
#               regionName: '$(TF_BACKEND_S3_REGION)'
#               bucketName: '$(TF_BACKEND_S3_BUCKET)'
#               sourceFolder: '$(Pipeline.Workspace)/rest_api/a'
#               globExpressions: '**'
#               targetFolder: '$(Build.BuildId)'
#               createBucket: true
#             displayName: 'upload Lambda function ZIP build to staging bucket'    
# Load secrets from Key Vault

# - stage: Build
#   jobs:
#   - job: FirstJob
#     steps:
#     - bash: ls -R $(Build.SourcesDirectory)
#     - bash: ls -R $(System.DefaultWorkingDirectory)
#     - bash: ls -R $(Build.ArtifactStagingDirectory)
- stage: DeployInfrastructure
  #dependsOn: DeployApp
  jobs:
  - deployment: DevDeployment
    pool:
      vmImage: 'ubuntu-latest'
    environment: 'Development'
    strategy:
      runOnce:
        deploy:
          steps:
          - task: TerraformInstaller@0
            displayName: 'Install Terraform latest'
          - bash: |
              terraform init -input=false
            displayName: Terraform Init
            env:
              AWS_ACCESS_KEY_ID:      $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY:  $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION:     $(TF_BACKEND_S3_REGION)
              AWS_SESSION_TOKEN:      $(AWS_SESSION_TOKEN)
            workingDirectory: '$(System.DefaultWorkingDirectory)/infrastructure'
          # steps:
          # - task: ms-devlabs.custom-terraform-tasks.custom-terraform-installer-task.TerraformInstaller@0
          #   displayName: 'Install Terraform latest'
          # - task: AWSShellScript@1
          #   inputs:
          #     awsCredentials: '${{ parameters.awsConnection }}'
          #     regionName: 'eu-central-1'
          #     scriptType: 'inline'
          #     inlineScript: |
          #       terraform -chdir=${{ parameters.path }} init \
          #           -backend-config="bucket=$(TF_BACKEND_S3_BUCKET)" \
          #           -backend-config="region=$(TF_BACKEND_S3_REGION)" \
          #           -backend-config="dynamodb_table=$(TF_BACKEND_S3_DYNAMODB_TABLE)"
          #       terraform -chdir=${{ parameters.path }} validate
          #       terraform -chdir=${{ parameters.path }} plan -detailed-exitcode
          #       echo $? > $(Pipeline.Workspace)/PLAN_CODE
          #       echo "##vso[task.setvariable variable=PLAN_CODE]$(cat $(Pipeline.Workspace)/PLAN_CODE)"
          #     disableAutoCwd: true
          #     workingDirectory: '$(Build.SourcesDirectory)/infrastructure '
          #     failOnStandardError: true
          #   env:
          #     AZDO_PERSONAL_ACCESS_TOKEN: $(AZDO_PERSONAL_ACCESS_TOKEN)
          #   displayName: Validate Terraform
# - stage: DeployInfrastructure
#   dependsOn: DeployApp
#   jobs:
#   - deployment: DevDeployment
#     pool:
#       vmImage: 'ubuntu-latest'
#     environment: 'Development'
#     strategy:
#       runOnce:
#         deploy:
#           steps:
#           - task: TerraformCLI@0
#             inputs:
#               command: 'init'
#               workingDirectory: '$(System.DefaultWorkingDirectory)/infrastructure'
#               backendType: 'aws'
#               allowTelemetryCollection: true
#               backendServiceAws: 'cicd_credential'
#               backendAwsRegion: 'eu-central-1'
#               backendAwsBucket: 'sample-project-ka2-state'
#               backendAwsKey: 'dev/backend-state'
#             displayName: 'Initialize Terraform'
#           - task: TerraformCLI@0
#             inputs:
#               command: 'fmt'
#               allowTelemetryCollection: true
#             displayName: 'Validate Terraform'
#           - task: TerraformCLI@0
#             inputs:
#               command: 'plan'
#               workingDirectory: '$(System.DefaultWorkingDirectory)/infrastructure'
#               allowTelemetryCollection: true
#               providerServiceAws: 'cicd_credential'
#               providerAwsRegion: 'eu-central-1'
#           - task: TerraformCLI@0
#             inputs:
#               command: 'apply'
#               workingDirectory: '$(System.DefaultWorkingDirectory)/infrastructure'
#               commandOptions: '-auto-approve -var deployment_number=$(Build.BuildId)'
#               allowTelemetryCollection: true
#               providerServiceAws: 'cicd_credential'
# - stage: DevelopmentDeployment
#   dependsOn: UploadArtifact
#   jobs:
#   - deployment: LambdaDevelopment
#     pool:
#       vmImage: 'ubuntu-latest'
#     environment: 'Development'
#     strategy:
#       runOnce:
#         deploy:
#           steps:
#           # - task: S3Upload@1
#           #   inputs:
#           #     awsCredentials: 'cicd_credential'
#           #     regionName: 'eu-central-1'
#           #     bucketName: 'sample-project-ka2-backend'
#           #     sourceFolder: '$(Pipeline.Workspace)/rest_api/a'
#           #     globExpressions: '**'
#           #     targetFolder: '$(Build.BuildId)'
#           #     createBucket: true
#           #   displayName: 'upload Lambda function ZIP build to staging bucket'
#           # - script: |
#           #     aws s3 cp $(Pipeline.Workspace)/rest_api/s/$(AWS_CLOUDFORMATION_TEMPLATE_FILE_NAME) s3://$(AWS_S3_STAGING_BUCKET_NAME)
#           #     aws s3 cp $(Pipeline.Workspace)/rest_api/a/rest_api.zip s3://$(AWS_S3_STAGING_BUCKET_NAME)
#           #   displayName: 'upload CloudFormation template and Lambda function ZIP build to staging bucket'
#           - script: |
#               aws cloudformation deploy --stack-name $(AWS_STACK_NAME_DEVELOPMENT) --template-file $(Pipeline.Workspace)/rest_api/s/$(AWS_CLOUDFORMATION_TEMPLATE_FILE_NAME) --tags Environment=Development --capabilities CAPABILITY_NAMED_IAM --no-fail-on-empty-changeset
#             displayName: 'updating CloudFormation stack'

# trigger:
# - main

# variables:
#   tag: '$(Build.BuildId)'

# stages:
# - stage: Build_Upload
#   displayName: Build Lambda Zip Files
#   jobs:
#   - job: BuildJob
#     pool:
#       vmImage: ubuntu-latest
#     steps:
#     - bash: echo building js files
#     - script: npm install
#       workingDirectory: $(System.DefaultWorkingDirectory)/backend
#       displayName: install node packages
#     - script: npm run build
#       workingDirectory: $(System.DefaultWorkingDirectory)/backend
#       displayName: build js files
#     - script: rm -rf node_modules
#       workingDirectory: $(System.DefaultWorkingDirectory)/backend
#       displayName: remove node modules
#     - script: zip -r rest_api.zip ./
#       workingDirectory: $(System.DefaultWorkingDirectory)/backend/build/
#       displayName: archive lambda
#     # - task: ArchiveFiles@2
#     #   inputs:
#     #     rootFolderOrFile: '$(System.DefaultWorkingDirectory)/backend/'
#     #     includeRootFolder: false
#     #     archiveType: 'zip'
#     #     archiveFile: 'rest-api.zip'
#     #     replaceExistingArchive: true

#     # - task: S3Upload@1
#     #   inputs:
#     #     awsCredentials: 'cicd_credential'
#     #     regionName: 'eu-central-1'
#     #     bucketName: 'sample-project-ka2-backend'
#     #     sourceFolder: '$(Build.ArtifactStagingDirectory)/rest-api.zip'
#     #     globExpressions: '**'
